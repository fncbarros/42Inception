***************************************************** DOCKER-COMPOSE *****************************************************

    -> Stop all containers and remove volumes: docker compose down -v

---------------------------------------------------
docker-compose.yml:
services:
   service:
   build: /path/to/dockerfile
   image: specify docker image
   restart: specify what to do if container crashes
   networks:	what network should the	container be a part of
   volumes:
	- path/to/disk/folder:path/to/container/folder:<permission_specification(optional)> (permissions: ro(read-o\
nly); rw(read-write))

---------------------------------------------------
ports:
 - "443:443"
    or
 - "127.0.0.1:443:443"

Specify both ports (HOST:CONTAINER),
specify just the container port (an ephemeral host port is chosen for the host port).
or specify the host IP address to bind to AND both ports (the default is 0.0.0.0, meaning all interfaces): (IPADDR:HOSTPORT:CONTAINERPORT). If HOSTPORT is empty (for example 127.0.0.1::80), an ephemeral port is chosen to bind to on the host.

Long form
ports:

  - target: 443     the port inside the container
    published: 443  the publicly exposed port
    protocol: tcp   the port protocol (tcp or udp)
    mode: host      host for publishing a host port on each node, or ingress for a swarm mode port to be load balanced.

---------------------------------------------------
expose: Expose ports without publishing them to the host
machine - they’ll only be accessible to linked services. Only the internal port can be specified.

***************************************************** DOCKER *****************************************************
    - List all containers and display only IDs: docker ps -q (or --quiet)
    - Stop all containers: docker stop $(docker ps -qa)
    - Remove all images: docker rmi $(docker images)
    - Remove all unused containers: docker rm $(docker ps -qa)
    - Remove all unused volumes: docker volume rm $(docker volume ls -q)
    - Remove all unused networks: docker network rm $(docker network ls -q) 2> /dev/null
    - Remove all unused data: docker system prune -a --volumes

***************************************************** Dockerfile *****************************************************

---------------------------------------------------
Multi-stage build example:
# syntax=docker/dockerfile:1
FROM golang:1.16-alpine AS build

# Install tools required for project
# Run `docker build --no-cache .` to update dependencies
RUN apk add --no-cache git
RUN go get github.com/golang/dep/cmd/dep

# List project dependencies with Gopkg.toml and Gopkg.lock
# These layers are only re-built when Gopkg files are updated
COPY Gopkg.lock Gopkg.toml /go/src/project/
WORKDIR /go/src/project/
# Install library dependencies
RUN dep ensure -vendor-only

# Copy the entire project and build it
# This layer is rebuilt when a file changes in the project directory
COPY . /go/src/project/
RUN go build -o /bin/project

# This results in a single layer image
FROM scratch
COPY --from=build /bin/project /bin/project
ENTRYPOINT ["/bin/project"]
CMD ["--help"]

---------------------------------------------------------------------------------------------------------------------------------------------------------
Although ADD and COPY are functionally similar, generally 
speaking, COPY is preferred. That’s because it’s more transparent than ADD.
COPY only supports the basic copying of local files into the container, while ADD has 
some features (like local-only tar extraction and remote URL support) that are not immediately obvious.
Consequently, the best use for ADD is local tar file 
auto-extraction into the image, as in ADD rootfs.tar.xz /.

---------------------------------------------------------------------------------------------------------------------------------------------------------
If you have multiple Dockerfile steps that use different files 
from your context, COPY them individually, rather than all at once.
This ensures that each step’s build cache is only invalidated, forcing the
step to be re-run if the specifically required files change.

---------------------------------------------------------------------------------------------------------------------------------------------------------
The main purpose of a CMD is to provide defaults for an executing container. 
These defaults can include an executable, or they can omit the executable, in which case you must specify an ENTRYPOINT instruction as well.

An ENTRYPOINT allows you to configure a container that will run as an executable.

Command line arguments to docker run <image> will be appended after all elements in an exec form ENTRYPOINT, and will override all elements specified using CMD

You can override the ENTRYPOINT instruction using the docker run --entrypoint flag.

---------------------------------------------------------------------------------------------------------------------------------------------------------
Adding "exec $@" at the end of your dockerfile-entrypoint.sh:
- $@" in list contexts expands to all the positional parameters{$1, $2, ...} as separate arguments.
- "exec" will replace the parent process

This is important so signals can be forwarded correctly.
If a container starts without exec, it might not receive a SIGTERM when the docker stop is run
and will not get a chance to shutdown cleanly. In some cases, this can lead to data loss or zombie processes.

If you do start child processes (i.e. don't use exec), the parent process becomes responsible for
handling and forwarding signals as appropriate. This is one of the reasons it's best to use supervisord or similar when
running multiple processes in a container, as it will forward signals appropriately.
(https://stackoverflow.com/questions/32255814/what-purpose-does-using-exec-in-docker-entrypoint-scripts-serve/32261019#32261019)

***************************************************** NGINX *****************************************************
https://www.nginx.com/resources/wiki/start/topics/tutorials/commandline/

/etc/nginx/nginx.conf

---------------------------------------------------
events {
}
 is mandatory

---------------------------------------------------
http {
    server {
        listen 443;

    location / {
        ...;
    }
    }
}
                                                    check syntax and test file with "nginx -t"

---------------------------------------------------
    # passing requests to proxied server
    location / {
        proxy_pass http://localhost:80;
    }

	# proxied server
    server {
        listen 80;
        root /data/up1;

        location / {
        }
    }

---------------------------------------------------
    # what you might want to do
    location / {
        proxy_pass http://php:9000;
    }

---------------------------------------------------
# nginx can be used to route requests to FastCGI servers which run applications
# built with various frameworks and programming languages such as PHP.

    # location [modifier(=|~|~*|...)] [URI (/|/images/)] {...}
    location / {
        fastcgi_pass localhost:9000;
        # SCRIPT_FILENAME PHP parameter to determine script name
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        # QUERY_STRING PHP parameter used to pass request parameters
        fastcgi_param QUERY_STRING    $query_string;
    }

    # regex matching all URIs ending with .jpg, or .png. All regex are preceded by ~.
	# This server will filter requests ending with .jpg, or .png and map them to 
	# the /data/images directory (by adding URI to the root directive’s parameter)
	# and pass all other requests to the proxied server configured above. 
	location ~\.(jpg|png)$ {
		root /data/images;
		}
---------------------------------------------------
Relevant files:
 - /etc/nginx/nginx.conf
 - /etc/hosts --> add "127.0.0.1 user.42.fr"
 - /etc/nginx/sites-enabled/default

---------------------------------------------------
And we start nginx with the "-g daemon off;" arguments to let it run on the foreground and apply the good practice rule of "one container, one process".
You can also include this option in your .conf file and just run nginx when you start your container.

I had a recurring 'nginx: invalid option: "off;"' error being thrown. If you added the 'exec $@' option at the end of your docker-entrypoint.sh like me,
you will want to leave your "$@" in quotes like I just did:
https://github.com/nginxinc/docker-nginx/issues/4#issuecomment-57379836

..................... SSL/TLS ...........................
La TLS (ou SSL) fonctionne suivant un mode client-serveur. Il permet de satisfaire les objectifs de sécurité suivants :

 - l'authentification du serveur ;
 - la confidentialité des données échangées (ou session chiffrée) ;
 - l'intégrité des données échangées ;
 - de manière optionnelle, l'authentification du client ;

-----------------------------------------------------
https://sectigo.com/resource-library/what-is-a-self-signed-certificate

- A self-signed SSL certificate is a digital certificate that’s not signed/validated by a publicly trusted Certificate Authority.
- Generally used in internal testing environments or web servers that are otherwise locked down to external users.
- They do not expire or need to be renewed, therefore they cannot comply with security updates in response to discovered vulnerabilities.
- Whenever a user visits a site that is using this certificate type, they will be prompted immediately with a security pop-up warning displaying errors like 
    “error_self_signed_cert” or “err_cert_authority_invalid” that require the user to confirm that they would like to proceed.

https://linuxize.com/post/creating-a-self-signed-ssl-certificate/

 - To create the SSL certificate both a private key file and a certificate signing request (CSR) are necessary.

..................... php ...........................
https://www.digitalocean.com/community/tutorials/how-to-install-linux-nginx-mysql-php-lemp-stack-on-ubuntu-20-04

